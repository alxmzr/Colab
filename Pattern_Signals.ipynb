{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alxmzr/Colab/blob/main/Pattern_Signals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfgdYPn0Qtl5"
      },
      "source": [
        "## Initial Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TvrlybxVLypy",
        "outputId": "f41ad00a-f1ee-4f37-b742-a5470f5bb80b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-adc7ba8d1d35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0myahoo_fin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstock_info\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpytictoc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTicToc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtalib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'yahoo_fin'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "#Importing Libraries\n",
        "#https://medium.datadriveninvestor.com/automating-technical-analysis-pattern-recognition-bcbc85e4ec3c\n",
        "import pandas as pd\n",
        "import datetime\n",
        "from datetime import date\n",
        "from datetime import timedelta\n",
        "import matplotlib.pyplot as plt\n",
        "import yahoo_fin.stock_info as si\n",
        "from pytictoc import TicToc\n",
        "import talib\n",
        "import numpy as np\n",
        "import mplfinance as mpf\n",
        "from talib import abstract\n",
        "t=TicToc()\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wYjJ0q-QtmK"
      },
      "source": [
        "### Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CvBFua2tQtmM"
      },
      "outputs": [],
      "source": [
        "##Getting Patterns\n",
        "\n",
        "def get_patterns(data=None,ticker_column = 'ticker',mute=False):\n",
        "    #from talib import abstract\n",
        "    result = pd.DataFrame()\n",
        "    tickers = data[ticker_column].unique()\n",
        "    x=[]\n",
        "    attr = talib.get_function_groups()['Pattern Recognition']\n",
        "    for i in tickers:\n",
        "        df = data[data[ticker_column]==i]\n",
        "        for a in attr:\n",
        "            df[a] = (getattr(abstract,a)(df))/100\n",
        "        result = pd.concat([result,df])\n",
        "        x.append(i)\n",
        "        if mute is False:\n",
        "            print(i + \" Patterns Appended Successfully\")\n",
        "            print(result.shape)\n",
        "            print(str(len(x)) + \" of \"+ str(len(tickers)) + \" Done \")\n",
        "        else:\n",
        "            pass\n",
        "    return result\n",
        "\n",
        "#Creating Indicators\n",
        "\n",
        "def get_indicators(data=None,ticker_column = 'ticker',price_column=\"close\",mute=False):\n",
        "    result = pd.DataFrame()\n",
        "    tickers = data[ticker_column].unique()\n",
        "    x=[]\n",
        "    for i in tickers:\n",
        "        df = data[data[ticker_column]==i]\n",
        "        df[\"Vol_over_30DAvg\"] = df[\"volume\"]/df[\"volume\"].rolling(window=30).mean()\n",
        "        df[\"Vol_over_10DAvg\"] = df[\"volume\"]/df[\"volume\"].rolling(window=10).mean()\n",
        "        df[\"Perc_From_200D_H\"] = ((df[price_column]/df[price_column].rolling(window=200).max())-1)*100\n",
        "        df[\"Perc_From_200D_L\"] = ((df[price_column]/df[price_column].rolling(window=200).min())-1)*100\n",
        "        df[\"Retracement_200D\"] = df[price_column]/(df[price_column].rolling(window=200).max()-df[price_column].rolling(window=30).min())\n",
        "        df[\"Perc_From_30D_H\"] = ((df[price_column]/df[price_column].rolling(window=30).max())-1)*100\n",
        "        df[\"Perc_From_30D_L\"] = ((df[price_column]/df[price_column].rolling(window=30).min())-1)*100\n",
        "        df[\"Retracement_30D\"] = df[price_column]/(df[price_column].rolling(window=30).max()-df[price_column].rolling(window=30).min())\n",
        "        df[\"30D/200D_High\"] = df[price_column].rolling(window=30).max()/df[price_column].rolling(window=200).max()\n",
        "        df[\"30D/200D_Low\"] = df[price_column].rolling(window=30).min()/df[price_column].rolling(window=200).min()\n",
        "        df[\"Perc_from 60DEMAVG\"] = ((df[price_column]/df[price_column].rolling(window=60).mean())-1)*100\n",
        "        df[\"Perc_from 30DEMAVG\"] = ((df[price_column]/df[price_column].rolling(window=30).mean())-1)*100\n",
        "        df[\"Perc_from 200DEMAVG\"] = ((df[price_column]/df[price_column].rolling(window=200).mean())-1)*100\n",
        "        df[\"Variand_30D/200D\"] = df[price_column].rolling(window=30).var()/df[price_column].rolling(window=200).var()\n",
        "        df = df.dropna()\n",
        "        df = df.sort_index(ascending=True)\n",
        "        result = pd.concat([result,df])\n",
        "        \n",
        "        if mute is False:\n",
        "            print(i + \" Indicators Appended Successfully\")\n",
        "            print(result.shape)\n",
        "            x.append(i)\n",
        "            print(str(len(x)) + \" of \"+ str(len(tickers)) + \" Done \")\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "    return result\n",
        "\n",
        "## Getting Labels\n",
        "\n",
        "def get_labels(data = None,ticker_column=\"ticker\", fwd_window=1,price_column=\"close\",threshold_perc=1,mute=False):\n",
        "    result = pd.DataFrame()\n",
        "    tickers = data[ticker_column].unique()\n",
        "    x=[]\n",
        "    for i in tickers:\n",
        "        df = data[data[ticker_column]==i]\n",
        "        df.sort_index(ascending=False)\n",
        "        df[\"Change\"] = df[price_column].pct_change(periods=fwd_window).shift(-fwd_window)\n",
        "        df[\"Change\"]=np.where(abs(df[\"Change\"])>=(threshold_perc/100),df[\"Change\"]/abs(df[\"Change\"]),0)\n",
        "        result= pd.concat([result,df],axis=0)\n",
        "        if mute is False:    \n",
        "            print(i + \" Labels Appended Successfully\")\n",
        "            print(result.shape)\n",
        "            x.append(i)\n",
        "            print(str(len(x)) + \" of \"+ str(len(tickers)) + \" Done \")\n",
        "        else:\n",
        "            pass\n",
        "    result.dropna(inplace=True)\n",
        "    return result\n",
        "\n",
        "\n",
        "## Compile Data\n",
        "\n",
        "def compile_data(data=None,ticker_column = 'ticker',price_column=\"close\",fwd_window=1,threshold_perc=1,mute=False,train=True):\n",
        "    print(\"Compiling pattern Signals\")\n",
        "    data_patterns = get_patterns(data=data,ticker_column=ticker_column,mute=mute)\n",
        "    print (\"---- Pattern Signals Attached\")\n",
        "    print(\"Compiling Indicators\")\n",
        "    data_indicators = get_indicators(data=data_patterns,ticker_column=ticker_column,price_column=price_column,mute=mute)\n",
        "    print (\"---- Indicators Attached\")\n",
        "    print (\"Creating Labels\")\n",
        "    data_labelled = get_labels(data=data_indicators,ticker_column=ticker_column,price_column=\"close\", fwd_window=fwd_window,threshold_perc=1,mute=mute)\n",
        "    print(\"---- All Labels Attached\")\n",
        "    if train is True:\n",
        "        return data_labelled\n",
        "    else:\n",
        "        return data_indicators\n",
        "\n",
        "#Getting Pattern based signals\n",
        "\n",
        "def get_pattern_signals(tickers=None,top=5):\n",
        "    d=pd.DataFrame()\n",
        "    start_date = date.today() - timedelta(days=200)\n",
        "    start_date= start_date.strftime('%m/%d/%Y')\n",
        "    end_date = date.today().strftime('%m/%d/%Y')\n",
        "    for i in tickers:\n",
        "        \n",
        "        a = si.get_data(ticker = i, start_date=start_date,end_date=end_date)\n",
        "        z = get_patterns(data=a,mute=True).iloc[-1,6:]\n",
        "        \n",
        "        d= pd.concat((d,z),axis=1)\n",
        "        print(i + \"   \",end=\"\\r\")\n",
        "    d.columns = d.iloc[0]\n",
        "    d=d.drop(\"ticker\")\n",
        "    d=d.sum()/d.count()\n",
        "    d=d.sort_values(ascending=False)\n",
        "    top_buy = d[d>0].head(top).sort_values(ascending=False)\n",
        "    top_sell = d[d<0].tail(top).sort_values(ascending=True)\n",
        "    print(\"Top Buy Ideas\")\n",
        "    print(top_buy)\n",
        "    print(\"Top Sell Ideas\")\n",
        "    print(top_sell)\n",
        "    return top_buy,top_sell\n",
        "\n",
        "## Getting Top MCap Tickers\n",
        "\n",
        "def get_top_tickers (index_name = 'sp500',top=50, tickers = None):\n",
        "    ''' For index_name, you can choose from the following:\\n\n",
        "        'sp500'   - S&P 500 Index \\n\n",
        "        'dow'     - Dow Jones Industrial Average \\n\n",
        "        'nasdaq'  - Companies listed on Nasdaq\\n\n",
        "        'nifty50' - For NIFTY50\\n\n",
        "        'ftse100' - For FTSE100\\n\n",
        "        'ftse250' - For FTSE250\\n\n",
        "        Or for any other index not listed above, a list of all the tickers can be passed to filter out Top N companies by Market Capitalization '''\n",
        "    mcap=[]\n",
        "    if tickers is None:\n",
        "        t = \"tickers_\"+index_name\n",
        "        tickers = getattr(si,t)()\n",
        "    else:\n",
        "        pass\n",
        "    for i in tickers:\n",
        "        a= si.get_quote_data(i)\n",
        "        b=round(a['sharesOutstanding']*a['regularMarketPrice']/1000000)\n",
        "        mcap.append(b)\n",
        "    mcap_df = pd.DataFrame()\n",
        "    mcap_df[\"Tickers\"] = tickers\n",
        "    mcap_df[\"MCap_mn\"] = mcap\n",
        "    mcap_df=mcap_df.sort_values(by=[\"MCap_mn\"],ascending=False)\n",
        "    top_mcap_tickers = mcap_df.head(top)[\"Tickers\"]\n",
        "    return top_mcap_tickers.to_list()\n",
        "\n",
        "## Getting Historical Bulk Data for Download\n",
        "\n",
        "def get_hist_data (tickers=None,time_window =1000,start_date=None,delta =1):\n",
        "    i_list=[]\n",
        "    data = pd.DataFrame()\n",
        "    if start_date is None:\n",
        "        start_date = date.today() - timedelta(days= time_window)\n",
        "        start_date= start_date.strftime('%m/%d/%Y')\n",
        "    else:\n",
        "        start_date= start_date.strftime('%m/%d/%Y')\n",
        "    end_date = date.today() - timedelta(days=delta)\n",
        "    end_date= end_date.strftime('%m/%d/%Y')\n",
        "    for i in tickers:\n",
        "        a = si.get_data(ticker = i, start_date=start_date,end_date=end_date)\n",
        "        data = pd.concat([data,a],axis=0)\n",
        "        print(i+\" Appended Successfully\")\n",
        "        print(data.shape)\n",
        "        i_list.append(i)\n",
        "        print(str(len(i_list)) + \" of \"+ str(len(tickers)) + \" Done \")\n",
        "        data.drop_duplicates(inplace = True)\n",
        "        data.dropna(inplace=True)\n",
        "    return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gzhfe96WQtmW"
      },
      "source": [
        "#### Selecting Top MCap Companies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LyfPzSXKQtmX"
      },
      "outputs": [],
      "source": [
        "top_100 = get_top_tickers(index_name='sp500',top=100)\n",
        "top_100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dzu0PgP7Qtmb"
      },
      "outputs": [],
      "source": [
        "top_100[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekQqw1LwQtmd"
      },
      "source": [
        "## Simple Pattern Based Signal Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EM91Ma2LQtme"
      },
      "outputs": [],
      "source": [
        "patterns = talib.get_function_groups()['Pattern Recognition']\n",
        "print(\"No. of patterns - \"+ str(len(patterns)))\n",
        "print(patterns[0:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgQ1awVbQtmg"
      },
      "outputs": [],
      "source": [
        "aapl = get_hist_data(tickers=[\"aapl\"],time_window=1000)\n",
        "aapl.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "neNVWJepQtmh"
      },
      "outputs": [],
      "source": [
        "aapl_patterns = get_patterns(data=aapl)\n",
        "aapl_patterns.iloc[:,-4:].tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cj0cV6YAQtmi"
      },
      "outputs": [],
      "source": [
        "aapl_patterns.iloc[:,:5].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DIRNj5Y2Qtmj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_VC3UanQtmk"
      },
      "outputs": [],
      "source": [
        "aapl_patterns[\"sum_flags\"] = aapl_patterns[patterns].sum(axis=1)\n",
        "print(\"Total Observation - \" + str(aapl_patterns.shape[0]))\n",
        "print(\"Observations with Flag - \" + str(aapl_patterns[aapl_patterns[\"sum_flags\"]!=0].shape[0]) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPP69EmlQtml"
      },
      "outputs": [],
      "source": [
        "print(patterns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MEeRckMhQtmm"
      },
      "outputs": [],
      "source": [
        "# Visualizing a pattern on candle stick chart\n",
        "\n",
        "aapl_engulfing = aapl_patterns['CDLENGULFING']\n",
        "aapl_engulfing_bullish = (aapl_engulfing.replace([-1,0],np.nan))*aapl_patterns.low*0.99\n",
        "aapl_engulfing_bearish = (-aapl_engulfing.replace([1,0],np.nan))*aapl_patterns.high*1.01\n",
        "%matplotlib ipympl\n",
        "addplot = [mpf.make_addplot(aapl_engulfing_bullish,type='scatter',color = 'g',marker = '^'), \n",
        "            mpf.make_addplot(aapl_engulfing_bearish,type='scatter',color = 'r',marker = 'v')]\n",
        "mpf.plot(aapl_patterns.iloc[:,:5],addplot=addplot,type='candle',style= 'yahoo')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6S-T2o3nQtmn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iXc6yWxKQtmo"
      },
      "outputs": [],
      "source": [
        "top_100[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpYtXdRgQtmp"
      },
      "outputs": [],
      "source": [
        "# Pattern based signal generation\n",
        "top_buy,top_sell=get_pattern_signals(tickers=top_100,top=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3IWdNllQtmp"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "orig_nbformat": 2,
    "vscode": {
      "interpreter": {
        "hash": "39577b162ef9ad5d6ce64c10fce0dc5ceae7a7a366573201898ab80ebb5ec546"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}