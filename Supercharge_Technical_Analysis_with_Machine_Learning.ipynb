{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPvhKrQztla6U9qdu0qhrJv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alxmzr/Colab/blob/main/Supercharge_Technical_Analysis_with_Machine_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Getting Historical Bulk Data for Download\n",
        "#https://medium.com/datadriveninvestor/supercharge-technical-analysis-with-machine-learning-af200909d824\n",
        "\n",
        "def get_hist_data (tickers=None,time_window =2000,start_date=None,delta =1,end_date=None):\n",
        "\n",
        "## Getting Historical Data\n",
        "data = get_hist_data(tickers=top_100,time_window=2000,delta=10)\n",
        "\n",
        "#Writing Data\n",
        "data.to_csv(r\"G:\\My Drive\\Personal Projects\\Project Curator\\Oct 2022\\Data_Top100_SP500.csv\")\n",
        "\n",
        "# Importing Saved Data\n",
        "\n",
        "data = pd.read_csv(r\"G:\\My Drive\\Personal Projects\\Project Curator\\Data_Top100_SP500.csv\",index_col=[0])\n"
      ],
      "metadata": {
        "id": "khermBfaMxzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of labels AAPL\n",
        "aapl = data[data[\"ticker\"]==\"AAPL\"]\n",
        "aapl_labelled = get_labels(data=aapl)\n",
        "aapl_labelled.tail(10)"
      ],
      "metadata": {
        "id": "0kvaiebAM7sf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3HFzfDXMJLt"
      },
      "outputs": [],
      "source": [
        "##Getting Patterns\n",
        "\n",
        "def get_patterns(data=None,ticker_column = 'ticker',mute=False):\n",
        "    #from talib import abstract\n",
        "    result = pd.DataFrame()\n",
        "    tickers = data[ticker_column].unique()\n",
        "    data = data.sort_index(ascending=True)\n",
        "    x=[]\n",
        "    attr = talib.get_function_groups()['Pattern Recognition']\n",
        "    for i in tickers:\n",
        "        df = data[data[ticker_column]==i]\n",
        "        for a in attr:\n",
        "            df[a] = (getattr(abstract,a)(df))/100\n",
        "        result = pd.concat([result,df])\n",
        "        x.append(i)\n",
        "        if mute is False:\n",
        "            print(i + \" Patterns Appended Successfully\")\n",
        "            print(result.shape)\n",
        "            print(str(len(x)) + \" of \"+ str(len(tickers)) + \" Done \")\n",
        "        else:\n",
        "            pass\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating Indicators\n",
        "\n",
        "def get_indicators(data=None,ticker_column = 'ticker',price_column=\"close\",mute=False):\n",
        "    result = pd.DataFrame()\n",
        "    tickers = data[ticker_column].unique()\n",
        "    x=[]\n",
        "    data = data.sort_index(ascending=True)\n",
        "    for i in tickers:\n",
        "        df = data[data[ticker_column]==i]\n",
        "        df[\"Vol_over_30DAvg\"] = df[\"volume\"]/df[\"volume\"].rolling(window=30).mean()\n",
        "        df[\"Vol_over_10DAvg\"] = df[\"volume\"]/df[\"volume\"].rolling(window=10).mean()\n",
        "        df[\"Perc_From_200D_H\"] = ((df[price_column]/df[price_column].rolling(window=200).max())-1)*100\n",
        "        df[\"Perc_From_200D_L\"] = ((df[price_column]/df[price_column].rolling(window=200).min())-1)*100\n",
        "        df[\"Retracement_200D\"] = df[price_column]/(df[price_column].rolling(window=200).max()-df[price_column].rolling(window=30).min())\n",
        "        df[\"Perc_From_30D_H\"] = ((df[price_column]/df[price_column].rolling(window=30).max())-1)*100\n",
        "        df[\"Perc_From_30D_L\"] = ((df[price_column]/df[price_column].rolling(window=30).min())-1)*100\n",
        "        df[\"Retracement_30D\"] = df[price_column]/(df[price_column].rolling(window=30).max()-df[price_column].rolling(window=30).min())\n",
        "        df[\"30D/200D_High\"] = df[price_column].rolling(window=30).max()/df[price_column].rolling(window=200).max()\n",
        "        df[\"30D/200D_Low\"] = df[price_column].rolling(window=30).min()/df[price_column].rolling(window=200).min()\n",
        "        df[\"Perc_from 60DEMAVG\"] = ((df[price_column]/df[price_column].rolling(window=60).mean())-1)*100\n",
        "        df[\"Perc_from 30DEMAVG\"] = ((df[price_column]/df[price_column].rolling(window=30).mean())-1)*100\n",
        "        df[\"Perc_from 200DEMAVG\"] = ((df[price_column]/df[price_column].rolling(window=200).mean())-1)*100\n",
        "        df[\"Variand_30D/200D\"] = df[price_column].rolling(window=30).var()/df[price_column].rolling(window=200).var()\n",
        "        df = df.dropna()\n",
        "        df = df.sort_index(ascending=True)\n",
        "        result = pd.concat([result,df])\n",
        "\n",
        "        if mute is False:\n",
        "            print(i + \" Indicators Appended Successfully\")\n",
        "            print(result.shape)\n",
        "            x.append(i)\n",
        "            print(str(len(x)) + \" of \"+ str(len(tickers)) + \" Done \")\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "sBnXVcfHMXK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Getting Labels\n",
        "\n",
        "def get_labels(data = None,ticker_column=\"ticker\", fwd_window=1,price_column=\"close\",threshold_perc=1,mute=False):\n",
        "    result = pd.DataFrame()\n",
        "    tickers = data[ticker_column].unique()\n",
        "    x=[]\n",
        "    data = data.sort_index(ascending=True)\n",
        "    for i in tickers:\n",
        "        df = data[data[ticker_column]==i]\n",
        "        df.sort_index(ascending=False)\n",
        "        df[\"Change\"] = df[price_column].pct_change(periods=fwd_window).shift(-fwd_window)\n",
        "        df[\"Change\"]=np.where(abs(df[\"Change\"])>=(threshold_perc/100),df[\"Change\"]/abs(df[\"Change\"]),0)\n",
        "        result= pd.concat([result,df],axis=0)\n",
        "        if mute is False:\n",
        "            print(i + \" Labels Appended Successfully\")\n",
        "            print(result.shape)\n",
        "            x.append(i)\n",
        "            print(str(len(x)) + \" of \"+ str(len(tickers)) + \" Done \")\n",
        "        else:\n",
        "            pass\n",
        "    result.dropna(inplace=True)\n",
        "    return result"
      ],
      "metadata": {
        "id": "bLpIJFVXMX6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Compile Data\n",
        "\n",
        "def compile_data(data=None,ticker_column = 'ticker',price_column=\"close\",train=True,\n",
        "fwd_window=1,threshold_perc=1,mute=False):\n",
        "    print(\"Compiling pattern Signals\")\n",
        "    data_patterns = get_patterns(data=data,ticker_column=ticker_column,mute=mute)\n",
        "    print (\"---- Pattern Signals Attached\")\n",
        "    print(\"Compiling Indicators\")\n",
        "    data_indicators = get_indicators(data=data_patterns,ticker_column=ticker_column,\n",
        "    price_column=price_column,mute=mute)\n",
        "    print (\"---- Indicators Attached\")\n",
        "    print (\"Creating Labels\")\n",
        "    if train is True:\n",
        "        data_labelled = get_labels(data=data_indicators,ticker_column=ticker_column,\n",
        "        price_column=\"close\", fwd_window=fwd_window,threshold_perc=1,mute=mute)\n",
        "        print(\"---- All Labels Attached\")\n",
        "        return data_labelled\n",
        "    else:\n",
        "        return data_indicators\n",
        "\n",
        "#Getting Pattern based signals\n",
        "\n",
        "def get_pattern_signals(tickers=None,top=5):\n",
        "    d=pd.DataFrame()\n",
        "    start_date = date.today() - timedelta(days=300)\n",
        "    start_date= start_date.strftime('%m/%d/%Y')\n",
        "    end_date = date.today().strftime('%m/%d/%Y')\n",
        "    for i in tickers:\n",
        "\n",
        "        a = si.get_data(ticker = i, start_date=start_date,end_date=end_date)\n",
        "        z = get_patterns(data=a,mute=True).iloc[-1,6:]\n",
        "\n",
        "        d= pd.concat((d,z),axis=1)\n",
        "        print(i + \"   \",end=\"\\r\")\n",
        "    d.columns = d.iloc[0]\n",
        "    d=d.drop(\"ticker\")\n",
        "    d=d.sum()/d.count()\n",
        "    d=d.sort_values(ascending=False)\n",
        "    top_buy = d[d>0].sort_values(ascending=False).head(top)\n",
        "    top_sell = d[d<0].sort_values(ascending=True).tail(top)\n",
        "    print(\"Top Buy Ideas\")\n",
        "    print(top_buy)\n",
        "    print(\"Top Sell Ideas\")\n",
        "    print(top_sell)\n",
        "    return top_buy,top_sell\n",
        "\n",
        "# Getting predictions\n",
        "\n",
        "def get_signals (data=None,tickers=None,model=None,ticker_column = 'ticker',price_column=\"close\",top=5):\n",
        "\n",
        "    if data is None:\n",
        "        data=get_hist_data(tickers=tickers,time_window=300,delta=0)\n",
        "\n",
        "    else:\n",
        "        data=data\n",
        "        tickers=data[ticker_column].unique()\n",
        "\n",
        "    result = pd.DataFrame()\n",
        "    for i in tickers:\n",
        "        compiled_data = compile_data(data=data[data[ticker_column]==i],ticker_column = 'ticker',\n",
        "        price_column=\"close\",train=False,mute=True)\n",
        "        prediction = predict_model(model,data=compiled_data).iloc[-1:,-2:]\n",
        "        result=pd.concat([result,prediction],axis=0)\n",
        "        print(i + \"- Prediction Attached\")\n",
        "    result[\"ticker\"] = tickers\n",
        "    top_buy = result[result[\"Label\"]>0].sort_values(by=['Score'],ascending=False).head(top)\n",
        "    top_sell = result[result[\"Label\"]<0].sort_values(by=['Score'],ascending=False).head(top)\n",
        "\n",
        "    return top_buy,top_sell\n",
        "\n",
        "## Getting Top MCap Tickers\n",
        "\n",
        "def get_top_tickers (index_name = 'sp500',top=50, tickers = None):\n",
        "    ''' For index_name, you can choose from the following:\\n\n",
        "        'sp500'   - S&P 500 Index \\n\n",
        "        'dow'     - Dow Jones Industrial Average \\n\n",
        "        'nasdaq'  - Companies listed on Nasdaq\\n\n",
        "        'nifty50' - For NIFTY50\\n\n",
        "        'ftse100' - For FTSE100\\n\n",
        "        'ftse250' - For FTSE250\\n\n",
        "        Or for any other index not listed above, a list of all the tickers can be passed to\n",
        "        filter out Top N companies by Market Capitalization '''\n",
        "    mcap=[]\n",
        "    if tickers is None:\n",
        "        t = \"tickers_\"+index_name\n",
        "        tickers = getattr(si,t)()\n",
        "    else:\n",
        "        pass\n",
        "    for i in tickers:\n",
        "        a= si.get_quote_data(i)\n",
        "        b=round(a['sharesOutstanding']*a['regularMarketPrice']/1000000)\n",
        "        mcap.append(b)\n",
        "    mcap_df = pd.DataFrame()\n",
        "    mcap_df[\"Tickers\"] = tickers\n",
        "    mcap_df[\"MCap_mn\"] = mcap\n",
        "    mcap_df=mcap_df.sort_values(by=[\"MCap_mn\"],ascending=False)\n",
        "    top_mcap_tickers = mcap_df.head(top)[\"Tickers\"]\n",
        "    return top_mcap_tickers.to_list()\n",
        "\n",
        "## Getting Historical Bulk Data for Download\n",
        "\n",
        "def get_hist_data (tickers=None,time_window =2000,start_date=None,delta =1,end_date=None):\n",
        "    i_list=[]\n",
        "    data = pd.DataFrame()\n",
        "\n",
        "    if end_date is None:\n",
        "        end_date = date.today() - timedelta(days=delta)\n",
        "    else:\n",
        "        end_date= end_date.strftime('%m/%d/%Y')\n",
        "\n",
        "    if start_date is None:\n",
        "        start_date = end_date - timedelta(days= time_window)\n",
        "        start_date= start_date.strftime('%m/%d/%Y')\n",
        "    else:\n",
        "        start_date= start_date.strftime('%m/%d/%Y')\n",
        "\n",
        "    for i in tickers:\n",
        "        a = si.get_data(ticker = i, start_date=start_date,end_date=end_date)\n",
        "        data = pd.concat([data,a],axis=0)\n",
        "        print(i+\" Appended Successfully\")\n",
        "        print(data.shape)\n",
        "        i_list.append(i)\n",
        "        print(str(len(i_list)) + \" of \"+ str(len(tickers)) + \" Done \")\n",
        "        data.drop_duplicates(inplace = True)\n",
        "        data.dropna(inplace=True)\n",
        "    return data"
      ],
      "metadata": {
        "id": "MIy3Fg9AMbaS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}